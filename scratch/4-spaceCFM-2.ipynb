{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import squidpy as sq\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import scprep\n",
    "from scvi.model import SCVI\n",
    "import torch\n",
    "import torchsde\n",
    "from torchdyn.core import NeuralODE\n",
    "from tqdm import tqdm\n",
    "from torchcfm.conditional_flow_matching import *\n",
    "from torchcfm.models import MLP, GradModel\n",
    "from torchcfm.utils import plot_trajectories, torch_wrapper\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from umap import UMAP\n",
    "import torch.nn as nn\n",
    "from torchdyn.core import NeuralODE\n",
    "import seaborn as sns\n",
    "from scvi.model import SCVI\n",
    "import scvi\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.stats import energy_distance\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821dc0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scRNA = ad.read_h5ad(\"data/combined_stereoSeq.h5ad\")\n",
    "print (\"Combined data shape: \", scRNA.shape)\n",
    "\n",
    "sc.pp.normalize_total(scRNA, target_sum=1e4)\n",
    "sc.pp.log1p(scRNA)\n",
    "sc.pp.highly_variable_genes(scRNA, flavor=\"seurat_v3\", n_top_genes=2000)\n",
    "scRNA = scRNA[:, scRNA.var.highly_variable]\n",
    "sc.pp.scale(scRNA, max_value=10)\n",
    "sc.tl.pca(scRNA, svd_solver='arpack')\n",
    "sc.pp.neighbors(scRNA)\n",
    "sc.tl.umap(scRNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cee90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot UMAP and PCA\n",
    "sc.pl.pca(scRNA, color=['Annotation', 'Batch'])\n",
    "sc.pl.umap(scRNA, color=['Annotation', 'Batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_local_mean(scRNA, representation='X_pca', spatial_key='spatial', radius=50):\n",
    "    \"\"\"\n",
    "    Compute mean vector of the chosen representation for spatial neighbors.\n",
    "    \n",
    "    Parameters:\n",
    "        scRNA: AnnData object\n",
    "        representation: str, key in .obsm, e.g. 'X_pca', 'X_umap', 'X_scVI'\n",
    "        spatial_key: str, key in .obsm with spatial coordinates\n",
    "        radius: float, neighborhood radius in same units as coordinates\n",
    "    \"\"\"\n",
    "    coords = scRNA.obsm[spatial_key]\n",
    "    X = scRNA.obsm[representation]\n",
    "\n",
    "    nbrs = NearestNeighbors(radius=radius).fit(coords)\n",
    "    neighbors_idx = nbrs.radius_neighbors(coords, return_distance=False)\n",
    "\n",
    "    local_means = np.zeros_like(X)\n",
    "\n",
    "    for i, idx in enumerate(neighbors_idx):\n",
    "        if len(idx) > 0:\n",
    "            local_means[i] = X[idx].mean(axis=0)\n",
    "        else:\n",
    "            local_means[i] = X[i]  \n",
    "\n",
    "    # Store the result in .obsm\n",
    "    scRNA.obsm[f\"local_mean\"] = local_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a9860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(scRNA, cell_type_key='Annotation', spatial_key = 'spatial', n_pca=50):\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    scRNA.obs[cell_type_key] = le.fit_transform(scRNA.obs[cell_type_key])\n",
    "    X_input = []\n",
    "    X_conditional = []\n",
    "    X_spatial = []\n",
    "    X_localmean = []\n",
    "\n",
    "    if (reducer == \"UMAP\"):\n",
    "        print (\"Using UMAP for input data\")\n",
    "        compute_local_mean(scRNA, representation='X_umap', radius=50)\n",
    "        for batch in scRNA.obs['Batch'].unique():\n",
    "            batch_data = scRNA[scRNA.obs['Batch'] == batch]\n",
    "            X_input.append(batch_data.obsm['X_umap'])\n",
    "            X_conditional.append(batch_data.obs[cell_type_key].values)\n",
    "            X_spatial.append(batch_data.obsm[spatial_key])\n",
    "            X_localmean.append(batch_data.obsm['local_mean'])\n",
    "            \n",
    "    elif (reducer == \"PCA\"):\n",
    "        print (\"Using PCA for input data\")\n",
    "        compute_local_mean(scRNA, representation='X_pca', radius=50)\n",
    "        for batch in scRNA.obs['Batch'].unique():\n",
    "            batch_data = scRNA[scRNA.obs['Batch'] == batch]\n",
    "            X_input.append(batch_data.obsm['X_pca'][:, :n_pca])\n",
    "            X_conditional.append(batch_data.obs[cell_type_key].values)\n",
    "            X_spatial.append(batch_data.obsm[spatial_key])\n",
    "            X_localmean.append(batch_data.obsm['local_mean'])\n",
    "\n",
    "    elif (reducer == \"scVI\"):\n",
    "        print (\"Using scVI for input data\")\n",
    "        #read the data (again cause scVI requires unormalized data) and set up scVI\n",
    "        scRNA = ad.read_h5ad(\"data/combined_stereoSeq.h5ad\")\n",
    "        le = LabelEncoder()\n",
    "        scRNA.obs[cell_type_key] = le.fit_transform(scRNA.obs[cell_type_key])\n",
    "        scvi.model.SCVI.setup_anndata(scRNA)\n",
    "        model = SCVI(scRNA)\n",
    "        model.train()\n",
    "        latent = model.get_latent_representation()\n",
    "        scRNA.obsm[\"X_scVI\"] = latent\n",
    "        compute_local_mean(scRNA, representation='X_scVI', radius=50)\n",
    "        \n",
    "        for batch in scRNA.obs['Batch'].unique():\n",
    "            batch_data = scRNA[scRNA.obs['Batch'] == batch]\n",
    "            X_input.append(batch_data.obsm['X_scVI'])\n",
    "            X_conditional.append(batch_data.obs[cell_type_key].values)\n",
    "            X_spatial.append(batch_data.obsm[spatial_key])\n",
    "            X_localmean.append(batch_data.obsm['local_mean'])\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported reducer type. Choose from 'UMAP', 'PCA', or 'scVI'.\")\n",
    "\n",
    "    return X_input, X_conditional, X_spatial, X_localmean\n",
    "\n",
    "reducer = \"scVI\"\n",
    "X_input, X_conditional, X_spatial, X_localmean = preprocess_data(scRNA)  \n",
    "n_times = len(X_input)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7fca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "params= {}  \n",
    "params['batch_size'] = 256\n",
    "params['sigma'] = 0.1\n",
    "params['dim'] = X_input[0].shape[1] + 1 # +1 for condition dimension\n",
    "params['learning_rate'] = 1e-4\n",
    "params['n_epochs'] = 10000\n",
    "params['out_dim'] = X_input[0].shape[1]\n",
    "params['w'] = 64\n",
    "params['time_varying'] = True\n",
    "params['lambda_'] = 1\n",
    "\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print (\"Using device: \", device)\n",
    "print (\"Input shape: \", params['dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b14b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(FM, X_input, X_conditional, X_localmean, batch_size, n_times, return_noise=False):\n",
    "    \"\"\"Construct a batch with points from each timepoint pair\"\"\"\n",
    "\n",
    "    ts = []\n",
    "    xts = []\n",
    "    uts = []\n",
    "    xts_conditional=[]\n",
    "    np.random.seed(42)\n",
    "\n",
    "    for t_start in range(n_times - 1):\n",
    "        b0 = np.random.randint(X_input[t_start].shape[0], size=batch_size)\n",
    "        b1 = np.random.randint(X_input[t_start+1].shape[0], size=batch_size)\n",
    "\n",
    "        x0 = (torch.from_numpy(X_input[t_start][b0]).float().to(device))\n",
    "        x1 = (torch.from_numpy(X_input[t_start + 1][b1]).float().to(device))\n",
    "\n",
    "        x0_conditional = (torch.from_numpy(X_conditional[t_start][b0]).long().to(device))\n",
    "\n",
    "        l0 = (torch.from_numpy(X_localmean[t_start][b0]).float().to(device))\n",
    "        l1 = (torch.from_numpy(X_localmean[t_start + 1][b1]).float().to(device))\n",
    "        \n",
    "        t, xt, ut = FM.sample_location_and_conditional_flow(x0, x1, p0 = l0, p1 = l1, lambda_ = 0.8, return_noise=return_noise)\n",
    "\n",
    "        ts.append(t + t_start)\n",
    "        xts.append(xt)\n",
    "        uts.append(ut)\n",
    "        xts_conditional.append(x0_conditional)\n",
    "\n",
    "    t = torch.cat(ts)\n",
    "    xt = torch.cat(xts)\n",
    "    ut = torch.cat(uts)\n",
    "    xts_conditional = torch.cat(xts_conditional)\n",
    "\n",
    "    return t, xt, ut, xts_conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f0e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(params, n_times, X_input, X_conditional):\n",
    "    \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    print (\"Using CUDA: \", use_cuda)\n",
    "\n",
    "    batch_size = params['batch_size']\n",
    "\n",
    "    ot_cfm_model = MLP(dim=params['dim'], out_dim=params['out_dim'], time_varying=params['time_varying'], w=params['w']).to(device)\n",
    "    ot_cfm_optimizer = torch.optim.Adam(ot_cfm_model.parameters(), params['learning_rate'])\n",
    "    FM = ExactOptimalTransportConditionalFlowMatcher(sigma=params['sigma'])\n",
    "\n",
    "    losses = []\n",
    "    for i in tqdm(range(params['n_epochs'])):\n",
    "        ot_cfm_optimizer.zero_grad()\n",
    "        t, xt, ut, xt_conditional = get_batch(FM, X_input, X_conditional, X_localmean, batch_size, n_times)\n",
    "        vt = ot_cfm_model(torch.cat([xt, xt_conditional[:, None], t[:, None]], dim=-1))\n",
    "        \n",
    "        loss = torch.mean((vt - ut) ** 2)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        ot_cfm_optimizer.step()\n",
    "\n",
    "    plt.plot(losses)\n",
    "\n",
    "    return ot_cfm_model\n",
    "\n",
    "ot_cfm_model= train(params, n_times,  X_input, X_conditional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a7463",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalODEVectorField(nn.Module):\n",
    "    def __init__(self, model, cond_dim, evolve_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.cond_dim = cond_dim\n",
    "        self.evolve_dim = evolve_dim\n",
    "        self.total_dim = cond_dim + evolve_dim\n",
    "\n",
    "    def forward(self, t, x, args=None):\n",
    "\n",
    "        if x.dim() > 1: # Handle batch dimension\n",
    "             t_expanded = t.expand(x.shape[0], 1) if isinstance(t, torch.Tensor) else torch.full((x.shape[0], 1), t, device=x.device, dtype=x.dtype)\n",
    "        else: # Handle single sample\n",
    "             t_expanded = t.reshape(1, 1) if isinstance(t, torch.Tensor) else torch.tensor([[t]], device=x.device, dtype=x.dtype)\n",
    "\n",
    "        model_input = torch.cat([x, t_expanded], dim=-1)\n",
    "\n",
    "        d_evolve_dt = self.model(model_input)\n",
    "        zeros_for_cond = torch.zeros_like(x[:, self.evolve_dim:self.total_dim])\n",
    "        full_derivative = torch.cat([d_evolve_dt, zeros_for_cond], dim=-1)\n",
    "        \n",
    "        assert full_derivative.shape == x.shape, \\\n",
    "            f\"Output derivative shape {full_derivative.shape} must match input state shape {x.shape}\"\n",
    "\n",
    "        return full_derivative\n",
    "    \n",
    "ode_field = ConditionalODEVectorField(ot_cfm_model, cond_dim=1, evolve_dim=params['out_dim'])\n",
    "node = NeuralODE(ode_field, solver=\"dopri5\", sensitivity=\"adjoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6481cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mmd_multi_rbf(X, Y, gammas=[2, 1, 0.5, 0.1, 0.01, 0.005]):\n",
    "    \"\"\"\n",
    "    Compute multi-kernel MMD^2 between X and Y with multiple RBF gammas.\n",
    "\n",
    "    X: [N, D]\n",
    "    Y: [M, D]\n",
    "    gammas: list of gamma values (1 / (2*sigma^2))\n",
    "\n",
    "    Returns:\n",
    "    mean MMD^2 across gammas\n",
    "    \"\"\"\n",
    "    XX = torch.cdist(X, X, p=2)**2\n",
    "    YY = torch.cdist(Y, Y, p=2)**2\n",
    "    XY = torch.cdist(X, Y, p=2)**2\n",
    "\n",
    "    m = X.size(0)\n",
    "    n = Y.size(0)\n",
    "\n",
    "    mmd_total = 0.0\n",
    "\n",
    "    for gamma in gammas:\n",
    "        K_XX = torch.exp(-gamma * XX)\n",
    "        K_YY = torch.exp(-gamma * YY)\n",
    "        K_XY = torch.exp(-gamma * XY)\n",
    "\n",
    "        mmd2 = (K_XX.sum() - torch.diagonal(K_XX).sum()) / (m * (m - 1)) \\\n",
    "             + (K_YY.sum() - torch.diagonal(K_YY).sum()) / (n * (n - 1)) \\\n",
    "             - 2 * K_XY.mean()\n",
    "\n",
    "        mmd_total += mmd2\n",
    "\n",
    "    mean_mmd = mmd_total / len(gammas)\n",
    "    return mean_mmd.item()\n",
    "\n",
    "def compute_wasserstein(X, Y):\n",
    "    # flatten to 1D for each feature or mean across features\n",
    "    X_flat = X.cpu().numpy().flatten()\n",
    "    Y_flat = Y.cpu().numpy().flatten()\n",
    "    return wasserstein_distance(X_flat, Y_flat)\n",
    "\n",
    "def compute_energy(X, Y):\n",
    "    X_flat = X.cpu().numpy().flatten()\n",
    "    Y_flat = Y.cpu().numpy().flatten()\n",
    "    return energy_distance(X_flat, Y_flat)\n",
    "\n",
    "def compute_r2(X, Y):\n",
    "    X_flat = X.cpu().numpy().flatten()\n",
    "    Y_flat = Y.cpu().numpy().flatten()\n",
    "    return r2_score(Y_flat, X_flat)\n",
    "\n",
    "\n",
    "def evaluate(node, X_input, device, steps=400, n_points=5000, plot_distributions=False):\n",
    "    mmd_list = []\n",
    "    wasserstein_list = []\n",
    "    energy_list = []\n",
    "    r2_list = []\n",
    "\n",
    "    for t in range(len(X_input) - 1):\n",
    "        print(f\"Evaluating: time {t} → {t+1}\")\n",
    "        \n",
    "        x0_np = X_input[t]\n",
    "        x1_np = X_input[t + 1]\n",
    "\n",
    "        n = min(n_points, min(len(x0_np), len(x1_np)))\n",
    "        idx = np.random.choice(min(len(x0_np), len(x1_np)), size=n, replace=False)\n",
    "\n",
    "        x0 = torch.tensor(x0_np[idx]).float().to(device)\n",
    "        x0_conditional = torch.tensor(X_conditional[t][idx]).long().to(device)\n",
    "        x1_true = torch.tensor(x1_np[idx]).float().to(device)\n",
    "\n",
    "        t_span = torch.linspace(0, 1, steps).to(device)\n",
    "        with torch.no_grad():\n",
    "            traj = node.trajectory(torch.cat([x0, x0_conditional.unsqueeze(-1).float()], dim=-1), t_span)\n",
    "        x1_pred = traj[-1]\n",
    "\n",
    "        x1_pred = x1_pred[:, :-1]  # Remove the conditional dimension\n",
    "\n",
    "        mmd_value = compute_mmd_multi_rbf(x1_pred.cpu(), x1_true.cpu())\n",
    "        wasserstein_value = compute_wasserstein(x1_pred, x1_true)\n",
    "        energy_value = compute_energy(x1_pred, x1_true)\n",
    "        r2_value = compute_r2(x1_pred, x1_true)\n",
    "\n",
    "        mmd_list.append(mmd_value)\n",
    "        wasserstein_list.append(wasserstein_value)\n",
    "        energy_list.append(energy_value)\n",
    "        r2_list.append(r2_value)\n",
    "\n",
    "        print (f\"t={t} → t+1: MMD={mmd_value:.4f}, Wasserstein={wasserstein_value:.4f}, \"\n",
    "               f\"Energy={energy_value:.4f}, R2={r2_value:.4f}\")\n",
    "\n",
    "        if plot_distributions:\n",
    "            plt.figure(figsize=(6,4))\n",
    "            sns.kdeplot(x1_pred.cpu().numpy().flatten(), label=\"Predicted\", fill=True)\n",
    "            sns.kdeplot(x1_true.cpu().numpy().flatten(), label=\"True\", fill=True)\n",
    "            plt.title(f\"Distribution at t={t+1}\")\n",
    "            plt.xlabel(\"Feature value (flattened)\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    return mmd_list, wasserstein_list, energy_list, r2_list\n",
    "\n",
    "mmd_list, wassersten_list, energy_list, r2_list = evaluate(node, X_input, device)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(range(len(mmd_list)), mmd_list, label='MMD', marker='o')\n",
    "plt.plot(range(len(wassersten_list)), wassersten_list, label='Wasserstein', marker='s')\n",
    "plt.plot(range(len(energy_list)), energy_list, label='Energy Distance', marker='^')\n",
    "#plt.plot(range(len(r2_list)), r2_list, label='R2 Score', marker='D')\n",
    "plt.xlabel(\"Timepoint t → t+1\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Distribution Matching Error\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
